# -*- coding: utf-8 -*-
"""Workshop.ipynb
##
Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19wMDQ7K-4SUsTU5TTR8xuv8qV80RGc4l
"""

! pip install spacy

from __future__ import unicode_literals, print_function

import plac
import random
import warnings
from pathlib import Path
import spacy
from spacy.util import minibatch, compounding

import json
import random
import spacy

with open('training_data .json', encoding='utf-8') as fh:
    data = json.load(fh)
TRAIN_DATA =data["annotations"]
print(TRAIN_DATA)

nlp = spacy.blank("en")
ner = nlp.create_pipe("ner")
nlp.add_pipe(ner, last=True)

for _, annotations in TRAIN_DATA:
        for ent in annotations.get("entities"):
            ner.add_label(ent[2])

nlp.begin_training()
for itn in range(100):
            random.shuffle(TRAIN_DATA)
            losses = {}
            # batch up the examples using spaCy's minibatch
            batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))
            for batch in batches:
                texts, annotations = zip(*batch)
                nlp.update(
                    texts,  # batch of texts
                    annotations,  # batch of annotations
                    drop=0.5,  # dropout - make it harder to memorise data
                    losses=losses,
                )
            print("Losses", losses)

nlp.to_disk("LEGAL_MODEL")
print("Saved model to")

nlp=spacy.load("Model_Workshop")

txs="betreffend das europ√§ische Patent 0 357 949.7"

doc=nlp(txs)

for ent in doc.ents:
  print(ent.text ,ent.label_)

from spacy import displacy

colors = {"PATENT": "linear-gradient(to bottom, #ccffff 0%, #99ff99 100%)"}
options = {"ents": ["PATENT"], "colors": colors}

displacy.render(doc, style="ent", options=options , jupyter= True)



"""# Nouvelle section"""
