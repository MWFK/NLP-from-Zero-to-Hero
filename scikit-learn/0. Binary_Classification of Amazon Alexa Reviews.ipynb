{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0. Binary Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNZqkaVHop/TXpTkX1fddCN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MWFK/NLP-from-Zero-to-Hero/blob/main/0_Binary_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onDnab0s45_s"
      },
      "source": [
        "# Libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqnl-EF94Imi"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from functools import lru_cache\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import metrics"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN3i2dPw7U14"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtflbQiA7CjJ",
        "outputId": "60376a8e-87f7-45af-f6ea-118df6b88ec3"
      },
      "source": [
        "# Source od the data https://www.kaggle.com/sid321axn/amazon-alexa-reviews\n",
        "df_amazon = pd.read_excel(r'/content/amazon_alexa.xlsx')\n",
        "print(df_amazon.shape)\n",
        "X         = df_amazon['verified_reviews'] \n",
        "ylabels   = df_amazon['feedback']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.25, shuffle=True, stratify=ylabels)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3150, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEbrN9Z48ODk"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RXSOalp717o"
      },
      "source": [
        "# configuration\n",
        "punctuations = string.punctuation\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "stop_words = spacy.lang.en.stop_words.STOP_WORDS"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCiK7Hdn8bQN"
      },
      "source": [
        "# Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DeAAICw8ToS"
      },
      "source": [
        "@lru_cache(maxsize=10000)\n",
        "def spacy_tokenizer(sentence):\n",
        "    \n",
        "    mytokens = []\n",
        "    # Remove trailling and overflow white spaces\n",
        "    #sentence = re.sub(\"\\s\\s+\" , \" \", sentence.strip()) #takes too much time\n",
        "    \n",
        "    # Lemmatizing each token and converting each token into lowercase\n",
        "    mytokens = [mytokens.append(word.lemma_) or word.lemma_ for word in nlp(re.sub(\"\\s\\s+\" , \" \", sentence.strip()))] # it automatically lowercase the letters\n",
        "\n",
        "    # Removing stop words and punctuation\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    return mytokens"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP9Z0BkV9P97"
      },
      "source": [
        "# Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pa1V4ag8hTJ",
        "outputId": "fd4ce1ce-4ea9-4990-d4e5-e9e05763dbaa"
      },
      "source": [
        "%%time\n",
        "\n",
        "text_clf = Pipeline([('vect' , CountVectorizer(tokenizer=spacy_tokenizer)),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf'  , LogisticRegression())])\n",
        "\n",
        "model     = text_clf.fit(X_train, y_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 15.7 s, sys: 69.3 ms, total: 15.8 s\n",
            "Wall time: 15.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnWVTqVs9gAA",
        "outputId": "31a02394-084a-4f03-b06f-794497453db3"
      },
      "source": [
        "predicted = model.predict(X_test)\n",
        "\n",
        "print(\"Logistic Regression Accuracy : {:0.4f}\".format(metrics.accuracy_score (y_test, predicted)))\n",
        "print(\"Logistic Regression Precision: {:0.4f}\".format(metrics.precision_score(y_test, predicted)))\n",
        "print(\"Logistic Regression Recall   : {:0.4f}\".format(metrics.recall_score   (y_test, predicted)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy : 0.9201\n",
            "Logistic Regression Precision: 0.9199\n",
            "Logistic Regression Recall   : 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBM6jiXG-2NG"
      },
      "source": [
        "# Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAdgQ6-Y-fjr",
        "outputId": "1bbf8d7d-c710-4962-a461-a8de8735283e"
      },
      "source": [
        "text_clf   = Pipeline([ ('tfidf', TfidfVectorizer()),               \n",
        "                        ('clf'  , SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42))])\n",
        "\n",
        "parameters = {'tfidf__ngram_range': [(1, 1), (1, 2)],              \n",
        "              'tfidf__use_idf'    : (True, False),\n",
        "              'clf__alpha'        : (1e-2, 1e-3)}\n",
        "\n",
        "gs_clf   = GridSearchCV(estimator=text_clf, param_grid=parameters, n_jobs=-1)\n",
        "model_gs = gs_clf.fit(X_train, y_train)\n",
        "\n",
        "print('{:0.4f}'.format(model_gs.best_score_))\n",
        "print(model_gs.best_params_)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9213\n",
            "{'clf__alpha': 0.001, 'tfidf__ngram_range': (1, 1), 'tfidf__use_idf': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMTMMwuE_KUx",
        "outputId": "a709fdb2-6de5-44f7-bd43-a4f171d64382"
      },
      "source": [
        "predicted = model_gs.predict(X_test)\n",
        "\n",
        "print(\"Logistic Regression Accuracy : {:0.4f}\".format(metrics.accuracy_score (y_test, predicted)))\n",
        "print(\"Logistic Regression Precision: {:0.4f}\".format(metrics.precision_score(y_test, predicted)))\n",
        "print(\"Logistic Regression Recall   : {:0.4f}\".format(metrics.recall_score   (y_test, predicted)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy : 0.9188\n",
            "Logistic Regression Precision: 0.9188\n",
            "Logistic Regression Recall   : 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUT-qeAWBFPJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
